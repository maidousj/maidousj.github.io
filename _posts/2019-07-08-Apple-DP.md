---
title: Learning with Privacy at Scale notes
layout: post
date: 2019-07-08 21:55
image: /assets/images/
headerImage: false
category: blog
tag:
- Local DP
- DP
- iOS
author: Sun
---

#### Introduction

苹果Differential Privacy Team写的[Learning with Privacy at Scale](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html#DR14)。介绍了苹果是怎么把差分隐私用在iOS中的。

>Our system is designed to be opt-in and transparent. No data is recorded or transmitted before the user explicitly chooses to report usage information. Data is privatized on the user’s device using event-level differential privacy [[4\]](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html#DNPR10) in the local model where an event might be, for example, a user typing an emoji. Additionally, we restrict the number of transmitted privatized events per use case. The transmission to the server occurs over an encrypted channel once per day, with no device identifiers. The records arrive on a restricted-access server where IP identifiers are immediately discarded, and any association between multiple records is also discarded. At this point, we cannot distinguish, for example, if an emoji record and a Safari web domain record came from the same user. The records are processed to compute statistics. These aggregate statistics are then shared internally with the relevant teams at Apple.

用了local-DP，传输是每天一次，通过加密隧道传输的，去掉了唯一标识的信息比如IP，去掉了多个记录之间的相互联系。这样看来的确是很强的保护了隐私。

> We focus on the problem of estimating frequencies of elements — for example, emojis and web domains. In estimating frequencies of elements, we consider two subproblems. In the first, we compute the histogram from a *known* dictionary of elements. In the second, the dictionary is *unknown* and we want to obtain a list of the most frequent elements in a dataset.

苹果主要关注对于emojis表情和web domians的使用频率。为此考虑两个子问题，计算已知字典的直方图和未知字典的最高频率使用的元素。

#### System Architecture

系统架构包括设备端(device-side)和服务器端(server-side)对数据的处理。在设备端，隐私化步骤保证了原始数据是符合DP的；服务端的数据处理可以切分成 *ingestion* 和 *aggregation* 两步。

![image-20190709095339093](/assets/images/image-apple-dp.png)

##### Privatization

用户可选是否开启共享隐私数据。对于开启共享的用户，为每个event设置一个隐私参数$\epsilon$。此外，还限制了用户每天可以传输的隐私数据数量。

> Our choice of $\epsilon$ is based on the privacy characteristics of the underlying dataset for each use case. These values are consistent with the parameters proposed in the differential privacy research community, such as [[5\]](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html#FPE16) and [[6\]](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html#QYYKX16).
>
> Moreover, the algorithms we present below provide users further deniability due to hash collisions. We provide additional privacy by removing user identifiers and IP addresses at the server where the records are separated by use case so that there is no association between multiple records.

去掉了用户标识和IP，按照use case划分records，这样可以切断记录之间的联系。

设备上产生一个event时，它就是$\epsilon$-local DP的，然后并不是立即发往服务器，而是通过苹果的data protection [[1\]](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html#AppleSecurity) (一种把数据加密存储在内存的技术) 把数据暂时存储在设备上。在根据设备条件延迟一段时间以后，系统从上述records中随机采样一些然后发送给服务器。这些记录不包括设备ID和event发生的时间戳等信息。通过TLS加密隧道发送到服务器。如图2所示。

![image-20190709162037937](/assets/images/image-apple-DP2.png)

(一点疑问，这个图看起来是经过加密了才发送到服务端的，那还用差分隐私做什么？)

![image-20190709163107472](/Users/sunjie/Documents/workspace/maidousj.github.io/assets/images/image-apple-DP3.png)

如图3所示为受欢迎的emoji表情统计算法的一个采样片段。records是一个128字节的16进制字符串。

##### Ingestion and Aggregation

私有化记录在进入Ingestion之前首先被去掉其IP地址。 然后，Ingestion从所有用户收集数据并批量处理它们。 批处理过程删除元数据，例如收到的私有化记录的时间戳，并根据用例分隔这些记录。 在将输出转发到下一阶段之前，摄取器还随机地置换每个用例中私有化记录的顺序。

