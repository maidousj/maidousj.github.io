---
title: Learning with Privacy at Scale notes
layout: post
date: 2019-07-08 21:55
image: /assets/images/
headerImage: false
category: blog
tag:
- Local DP
- DP
- iOS
author: Sun
---

#### Introduction

苹果Differential Privacy Team写的[Learning with Privacy at Scale](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html#DR14)。介绍了苹果是怎么把差分隐私用在iOS中的。

>Our system is designed to be opt-in and transparent. No data is recorded or transmitted before the user explicitly chooses to report usage information. Data is privatized on the user’s device using event-level differential privacy [[4\]](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html#DNPR10) in the local model where an event might be, for example, a user typing an emoji. Additionally, we restrict the number of transmitted privatized events per use case. The transmission to the server occurs over an encrypted channel once per day, with no device identifiers. The records arrive on a restricted-access server where IP identifiers are immediately discarded, and any association between multiple records is also discarded. At this point, we cannot distinguish, for example, if an emoji record and a Safari web domain record came from the same user. The records are processed to compute statistics. These aggregate statistics are then shared internally with the relevant teams at Apple.

用了local-DP，传输是每天一次，通过加密隧道传输的，去掉了唯一标识的信息比如IP，去掉了多个记录之间的相互联系。这样看来的确是很强的保护了隐私。

> We focus on the problem of estimating frequencies of elements — for example, emojis and web domains. In estimating frequencies of elements, we consider two subproblems. In the first, we compute the histogram from a *known* dictionary of elements. In the second, the dictionary is *unknown* and we want to obtain a list of the most frequent elements in a dataset.

苹果主要关注对于emojis表情和web domians的使用频率。为此考虑两个子问题，计算已知字典的直方图和未知字典的最高频率使用的元素。

#### System Architecture

系统架构包括设备端(device-side)和服务器端(server-side)对数据的处理。在设备端，隐私化步骤保证了原始数据是符合DP的；服务端的数据处理可以切分成 *ingestion* 和 *aggregation* 两步。

![image-20190709095339093](/assets/images/image-apple-dp.png)

##### Privatization

用户可选是否开启共享隐私数据。对于开启共享的用户，为每个event设置一个隐私参数$\epsilon$。此外，还限制了用户每天可以传输的隐私数据数量。

> Our choice of $\epsilon$ is based on the privacy characteristics of the underlying dataset for each use case. These values are consistent with the parameters proposed in the differential privacy research community, such as [[5\]](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html#FPE16) and [[6\]](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html#QYYKX16).
>
> Moreover, the algorithms we present below provide users further deniability due to hash collisions. We provide additional privacy by removing user identifiers and IP addresses at the server where the records are separated by use case so that there is no association between multiple records.

去掉了用户标识和IP，按照use case划分records，这样可以切断记录之间的联系。

设备上产生一个event时，它就是$\epsilon$-local DP的，然后并不是立即发往服务器，而是通过苹果的data protection [[1\]](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html#AppleSecurity) (一种把数据加密存储在内存的技术) 把数据暂时存储在设备上。在根据设备条件延迟一段时间以后，系统从上述records中随机采样一些然后发送给服务器。这些记录不包括设备ID和event发生的时间戳等信息。通过TLS加密隧道发送到服务器。如图2所示。

![image-20190709162037937](/assets/images/image-apple-DP2.png)

(一点疑问，这个图看起来是经过加密了才发送到服务端的，那还用差分隐私做什么？)

![image-20190709163107472](/assets/images/image-apple-DP3.png)

如图3所示为受欢迎的emoji表情统计算法的一个采样片段。records是一个128字节的16进制字符串。

##### Ingestion and Aggregation

私有化记录在进入Ingestor之前首先被去掉其IP地址。 然后，Ingestor从所有用户收集数据并批量处理它们。 批处理过程删除元数据，例如收到的私有化记录的时间戳，并根据用例分隔这些记录。 在将输出转发到下一阶段之前，Ingestor还随机地置换每个用例中私有化记录的顺序。

Aggregator从Ingestor中获取到records，为每个用例生成一个符合DP的直方图。计算统计信息时，来自多个用例的数据永远不会合并。在这些直方图中，仅包括计数高于规定阈值T的域元素。

(疑问：这个用例是指什么，每个人的统计信息吗？)

#### Algorithms

##### Private Count Mean Sketch

The Private Count Mean Sketch algorithm (CMS) 有两个步骤：客户端处理和服务器端聚合。

一个例子：假设某个用户访问了www.example.com这个网址。

**客户端算法**会从k个hash函数中$\{h_1, h_2, \dots, h_k\}$随机选一个，假设选了$h_2$。$h_2(www.example.com) = 31$。然后用一个长度为m的向量对31进行one-hot编码，第31位为1。为了保证DP，这个向量的每一位都以$\frac{1}{e^{\epsilon/2}+1}$的概率进行flip (1变为0，0变为1) 操作。最后这个向量和hash函数的index $j$被发送到服务器。

**服务器端算法**通过聚合上述来自设备端的隐私向量构造一个*sketch matrix M*。该矩阵有k行，每行是一个hash函数；m列代表从客户端传输的长度为m的向量。

当records到达服务器时，算法把privatized vector加入到第$j$行















